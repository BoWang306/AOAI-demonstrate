# 🎬 Azure OpenAI 模型测试门户 - 演示脚本

## 场景 1: 快速启动 (30 秒)

### 目标
展示如何快速启动应用

### 步骤
```bash
# 1. 克隆项目
git clone <repository-url>
cd webapp

# 2. 快速启动
./start.sh

# 3. 打开浏览器
# 访问 http://localhost:8501
```

### 演示要点
- ✅ 一键启动
- ✅ 自动安装依赖
- ✅ 快速访问应用

---

## 场景 2: Dev Container 开发 (1 分钟)

### 目标
展示 Dev Container 的便利性

### 步骤
```bash
# 1. 在 VS Code 中打开项目
code /path/to/webapp

# 2. 点击提示 "Reopen in Container"
# 或 F1 → "Dev Containers: Reopen in Container"

# 3. 等待容器构建完成

# 4. 在集成终端运行
streamlit run app.py
```

### 演示要点
- ✅ 统一开发环境
- ✅ 自动配置
- ✅ 预装扩展
- ✅ 零配置开发

---

## 场景 3: 配置 API (1 分钟)

### 目标
展示如何配置 Azure OpenAI API

### 方式 A: 使用界面配置

#### 步骤
1. 打开应用侧边栏
2. 找到 "⚙️ 配置" 部分
3. 输入配置信息：
   - API Key: `your_api_key`
   - API Base URL: `https://your-resource.openai.azure.com/`
   - API Version: `2024-02-15-preview`
4. 点击 "💾 保存配置"

### 方式 B: 使用环境变量

#### 步骤
```bash
# 1. 复制模板
cp .env.example .env

# 2. 编辑配置
nano .env

# 3. 填入信息
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# 4. 重启应用
```

### 演示要点
- ✅ 两种配置方式
- ✅ 环境变量支持
- ✅ 简单易用

---

## 场景 4: 聊天测试 (2 分钟)

### 目标
展示聊天模式的交互体验

### 步骤

1. **选择模型**
   - 侧边栏 → "🎯 模型选择"
   - 模型系列: GPT-5
   - 具体模型: gpt-5-nano

2. **调整参数**
   - Temperature: 0.7
   - Max Tokens: 500
   - 开启流式输出

3. **开始对话**
   
   **第一轮**:
   ```
   用户: 你好！请用一句话介绍一下机器学习。
   AI: [实时流式响应]
   ```
   
   **第二轮**:
   ```
   用户: 它和深度学习有什么区别？
   AI: [基于上下文的回复]
   ```

4. **查看指标**
   - 延迟时间
   - Token 使用量
   - 成本估算

### 演示要点
- ✅ 流式输出体验
- ✅ 多轮对话
- ✅ 上下文理解
- ✅ 实时指标

---

## 场景 5: 单次调用测试 (2 分钟)

### 目标
展示单次 API 调用的详细信息

### 步骤

1. **切换到 "📝 单次调用" 标签**

2. **配置 Prompt**
   
   **System Prompt**:
   ```
   你是一个专业的 Python 编程助手，
   擅长编写清晰、高效、有注释的代码。
   ```
   
   **User Prompt**:
   ```
   写一个 Python 函数，计算斐波那契数列的第 n 项。
   要求：
   1. 使用递归方式
   2. 添加完整注释
   3. 包含使用示例
   ```

3. **发送请求**
   - 点击 "🚀 发送请求"
   - 等待响应

4. **查看结果**
   - 生成的代码
   - 性能指标（延迟、Tokens）
   - 完整 JSON 响应

### 演示要点
- ✅ System Prompt 作用
- ✅ 详细的响应信息
- ✅ JSON 格式查看
- ✅ 性能监控

---

## 场景 6: 批量测试 (3 分钟)

### 目标
展示批量测试功能

### 方式 A: 手动输入

#### 步骤

1. **切换到 "📊 批量测试" 标签**

2. **选择 "手动输入" 模式**

3. **配置测试用例**
   
   **测试用例 1**:
   - 名称: 基础问候
   - Prompt: 你好，请介绍你自己
   
   **测试用例 2**:
   - 名称: 技术解释
   - Prompt: 用简单语言解释什么是 API
   
   **测试用例 3**:
   - 名称: 代码生成
   - Prompt: 用 Python 写一个 Hello World

4. **运行测试**
   - 点击 "🚀 开始批量测试"
   - 观察进度条
   - 查看实时状态

5. **查看结果**
   - 每个用例的响应
   - 性能指标对比
   - 汇总统计
   - 导出结果

### 方式 B: JSON 文件上传

#### 步骤

1. **准备 JSON 文件**
   ```json
   [
     {
       "name": "测试用例1",
       "prompt": "解释什么是机器学习"
     },
     {
       "name": "测试用例2",
       "prompt": "写一首关于春天的诗"
     }
   ]
   ```

2. **上传文件**
   - 选择 "上传 JSON 文件"
   - 点击上传按钮
   - 选择 JSON 文件

3. **运行和查看结果**
   - 同上

### 演示要点
- ✅ 两种输入方式
- ✅ 批量处理能力
- ✅ 进度实时显示
- ✅ 结果汇总统计
- ✅ 结果导出功能

---

## 场景 7: 参数调优对比 (3 分钟)

### 目标
展示不同参数对输出的影响

### 测试 A: 低 Temperature

#### 配置
- Model: gpt-5
- Temperature: 0.1
- Max Tokens: 200

#### Prompt
```
用三个词描述春天
```

#### 预期结果
- 输出稳定、一致
- 更加保守、常规

### 测试 B: 高 Temperature

#### 配置
- Model: gpt-5
- Temperature: 1.2
- Max Tokens: 200

#### Prompt
```
用三个词描述春天
```

#### 预期结果
- 输出多样、创意
- 更加新颖、不同

### 演示要点
- ✅ Temperature 的作用
- ✅ 参数对输出的影响
- ✅ 如何选择合适参数

---

## 场景 8: 模型对比 (3 分钟)

### 目标
对比不同模型的表现

### 测试配置

#### Prompt (相同)
```
写一个关于人工智能的 50 字短文
```

#### 模型 A: gpt-5-nano
- 快速响应
- 基础质量
- 成本低

#### 模型 B: gpt-5
- 中等速度
- 良好质量
- 成本适中

#### 模型 C: gpt-5-pro
- 较慢响应
- 高质量
- 成本高

### 对比维度
1. **响应速度**（延迟）
2. **输出质量**（连贯性、创意）
3. **Token 使用量**
4. **成本效益**

### 演示要点
- ✅ 不同模型特点
- ✅ 性能与质量权衡
- ✅ 如何选择模型

---

## 场景 9: Docker 部署 (2 分钟)

### 目标
展示 Docker 部署的便利性

### 步骤

```bash
# 1. 使用 Docker Compose
cd /path/to/webapp
docker-compose -f .devcontainer/docker-compose.yml up -d

# 2. 查看日志
docker-compose -f .devcontainer/docker-compose.yml logs -f

# 3. 访问应用
# 打开 http://localhost:8501

# 4. 停止服务
docker-compose -f .devcontainer/docker-compose.yml down
```

### 演示要点
- ✅ 容器化部署
- ✅ 一键启动
- ✅ 环境隔离
- ✅ 易于管理

---

## 场景 10: 配置助手 (1 分钟)

### 目标
展示配置验证工具

### 步骤

```bash
# 1. 运行配置助手
streamlit run config_helper.py

# 2. 输入配置信息
API Key: your_key
API Base URL: https://your-resource.openai.azure.com/
API Version: 2024-02-15-preview
测试模型: gpt-4.1-nano

# 3. 点击 "🧪 测试连接"

# 4. 查看结果
✅ 连接成功
📤 测试响应
📊 性能指标
💾 配置保存建议
```

### 演示要点
- ✅ 快速验证配置
- ✅ 友好的错误提示
- ✅ 配置保存建议

---

## 完整演示流程 (15 分钟)

### 1. 介绍 (1 分钟)
- 项目背景
- 主要功能
- 支持的模型

### 2. 快速启动 (2 分钟)
- Dev Container 方式
- 本地启动方式
- Docker 部署方式

### 3. 配置 API (1 分钟)
- 界面配置
- 环境变量配置

### 4. 核心功能演示 (8 分钟)
- 聊天测试 (2 分钟)
- 单次调用 (2 分钟)
- 批量测试 (2 分钟)
- 参数调优 (2 分钟)

### 5. 高级功能 (2 分钟)
- 模型对比
- 性能监控
- 结果导出

### 6. 总结 (1 分钟)
- 主要优势
- 使用场景
- 获取帮助

---

## 演示技巧

### 准备工作
- ✅ 提前配置好 API
- ✅ 准备好测试 Prompt
- ✅ 准备批量测试 JSON
- ✅ 清空浏览器缓存

### 演示建议
- 🎯 突出核心功能
- 🎯 展示实际用例
- 🎯 说明性能指标
- 🎯 对比不同模型

### 互动环节
- 💬 邀请观众提问
- 💬 现场测试观众的 Prompt
- 💬 讨论实际应用场景

### 常见问题准备
1. 如何获取 API Key？
2. 支持哪些模型？
3. 如何选择合适的参数？
4. 成本如何计算？
5. 可以部署到生产环境吗？
6. 支持团队协作吗？
7. 如何扩展功能？
8. 有文档吗？

---

## 演示素材

### 推荐测试 Prompt

#### 1. 基础对话
```
你好！请用 50 字介绍一下你自己。
```

#### 2. 技术解释
```
用简单的语言解释什么是 Transformer 架构，
不超过 100 字，适合非技术人员理解。
```

#### 3. 代码生成
```
用 Python 写一个函数，实现二分查找算法。
要求：
1. 完整的函数定义
2. 详细的注释
3. 包含使用示例
4. 处理边界情况
```

#### 4. 创意写作
```
写一个关于机器人学会感受情感的 100 字短故事，
要有转折，结局温馨。
```

#### 5. 数据分析
```
分析以下销售数据的趋势和建议：
2021: 100万
2022: 120万
2023: 150万
2024: 180万
```

### 批量测试 JSON 示例

```json
[
  {
    "name": "问候测试",
    "prompt": "你好，请介绍一下你自己"
  },
  {
    "name": "知识问答",
    "prompt": "什么是量子计算？"
  },
  {
    "name": "代码生成",
    "prompt": "用 Python 实现快速排序"
  },
  {
    "name": "翻译任务",
    "prompt": "将 'Hello World' 翻译成中文、日文和法文"
  },
  {
    "name": "创意写作",
    "prompt": "写一首关于秋天的现代诗"
  }
]
```

---

**演示准备完成！祝演示顺利！🎬**
