"""
Azure OpenAI èŠå¤©æµ‹è¯•
æ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡è¾“å…¥ï¼Œä½¿ç”¨ Responses API
"""

import streamlit as st
from openai import OpenAI
import json
from pathlib import Path
import base64
import time
from io import BytesIO
from PIL import Image

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="GPT èŠå¤©æµ‹è¯•",
    page_icon="ğŸ’¬",
    layout="wide"
)

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = Path("config.json")

# åŠ è½½é…ç½®
def load_config():
    if CONFIG_FILE.exists():
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return {}
    return {}

# ä¿å­˜é…ç½®
def save_config(config):
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except:
        return False

# ç¼–ç å›¾ç‰‡ä¸º base64
def encode_image(image_file):
    """å°†ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸º base64 URL"""
    try:
        # è¯»å–å›¾ç‰‡
        image = Image.open(image_file)
        # è½¬æ¢ä¸º RGBï¼ˆå¦‚æœæ˜¯ RGBAï¼‰
        if image.mode == 'RGBA':
            image = image.convert('RGB')
        
        # ä¿å­˜åˆ°å­—èŠ‚æµ
        buffered = BytesIO()
        image.save(buffered, format="JPEG")
        img_bytes = buffered.getvalue()
        
        # ç¼–ç ä¸º base64
        img_base64 = base64.b64encode(img_bytes).decode('utf-8')
        return f"data:image/jpeg;base64,{img_base64}"
    except Exception as e:
        st.error(f"å›¾ç‰‡ç¼–ç å¤±è´¥: {str(e)}")
        return None

# åˆå§‹åŒ– session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'config' not in st.session_state:
    st.session_state.config = load_config()

# æ ‡é¢˜
st.title("ğŸ’¬ GPT èŠå¤©æµ‹è¯•")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ èŠå¤©æ¨¡å‹é…ç½®")
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½èŠå¤©æ¨¡å‹çš„é…ç½®
    chat_config = st.session_state.config.get('chat', {})
    
    # API é…ç½®
    api_key = st.text_input(
        "API Key", 
        type="password", 
        value=chat_config.get('api_key', ''),
        key="chat_api_key"
    )
    endpoint = st.text_input(
        "Endpoint (Base URL)", 
        placeholder="https://your-resource.openai.azure.com/openai/deployments/your-model",
        value=chat_config.get('endpoint', ''),
        key="chat_endpoint",
        help="å®Œæ•´çš„éƒ¨ç½² URL"
    )
    model = st.text_input(
        "æ¨¡å‹åç§°", 
        value=chat_config.get('model', 'gpt-4o'),
        key="chat_model"
    )
    
    # ä¿å­˜é…ç½®æŒ‰é’®
    if st.button("ğŸ’¾ ä¿å­˜èŠå¤©é…ç½®", use_container_width=True):
        config = st.session_state.config
        config['chat'] = {
            'api_key': api_key,
            'endpoint': endpoint,
            'model': model
        }
        if save_config(config):
            st.session_state.config = config
            st.success("âœ… èŠå¤©é…ç½®å·²ä¿å­˜ï¼")
        else:
            st.error("âŒ ä¿å­˜å¤±è´¥")
    
    st.divider()
    
    # å‚æ•°è®¾ç½®
    st.subheader("ğŸ”§ å‚æ•°")
    
    # Reasoning effort
    reasoning_effort = st.selectbox(
        "Reasoning Effort",
        options=["none", "minimal", "low", "medium", "high"],
        index=0,
        help="æ¨ç†çº§åˆ«ï¼ˆä»…æ”¯æŒ GPT-5 ç³»åˆ—å’Œ o ç³»åˆ—ï¼‰"
    )
    
    st.divider()
    
    # æ¸…ç©ºæŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# æ˜¾ç¤ºå¯¹è¯å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # æ˜¾ç¤ºæ–‡æœ¬
        if "text" in message:
            st.write(message["text"])
        
        # æ˜¾ç¤ºå›¾ç‰‡
        if "image" in message:
            st.image(message["image"], width=300)

# å›¾ç‰‡ä¸Šä¼ 
uploaded_file = st.file_uploader("ğŸ“ ä¸Šä¼ å›¾ç‰‡ï¼ˆå¯é€‰ï¼‰", type=['png', 'jpg', 'jpeg'], key="image_upload")

# ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯..."):
    # æ£€æŸ¥é…ç½®
    if not api_key or not endpoint:
        st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key å’Œ Endpoint")
    else:
        # æ„é€ ç”¨æˆ·æ¶ˆæ¯
        user_message = {"role": "user", "text": prompt}
        
        # å¤„ç†å›¾ç‰‡
        image_data = None
        if uploaded_file is not None:
            image_data = encode_image(uploaded_file)
            if image_data:
                user_message["image"] = uploaded_file
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append(user_message)
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.write(prompt)
            if uploaded_file is not None and image_data:
                st.image(uploaded_file, width=300)
        
        # è°ƒç”¨ API
        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = OpenAI(
                base_url=endpoint,
                api_key=api_key,
            )
            
            # æ„é€  inputï¼ˆä½¿ç”¨ Responses API æ ¼å¼ï¼‰
            content = [
                {
                    "type": "input_text",
                    "text": prompt
                }
            ]
            
            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ åˆ° content
            if image_data:
                content.append({
                    "type": "input_image",
                    "image_url": image_data
                })
            
            input_items = [
                {
                    "type": "message",
                    "role": "user",
                    "content": content
                }
            ]
            
            # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                metrics_placeholder = st.empty()
                
                full_response = ""
                first_token_time = None
                start_time = time.time()
                reasoning_tokens = 0
                total_tokens = 0
                
                # æµå¼è¯·æ±‚
                reasoning_config = {"effort": reasoning_effort} if reasoning_effort != "none" else None
                
                stream = client.responses.create(
                    model=model,
                    input=input_items,
                    stream=True,
                    reasoning=reasoning_config
                )
                
                # å¤„ç†æµå¼äº‹ä»¶
                for event in stream:
                    # æ•è·æ–‡æœ¬å¢é‡
                    if event.type == "response.output_text.delta":
                        if first_token_time is None:
                            first_token_time = time.time()
                        
                        if hasattr(event, 'delta') and event.delta:
                            full_response += event.delta
                            message_placeholder.write(full_response)
                    
                    # æ•è·å®Œæˆäº‹ä»¶ï¼Œæå– tokens
                    elif event.type == "response.completed":
                        if hasattr(event, 'response') and event.response and hasattr(event.response, 'usage'):
                            usage = event.response.usage
                            
                            # æå– Total Tokens
                            if hasattr(usage, 'total_tokens'):
                                total_tokens = usage.total_tokens
                            
                            # æå– Reasoning Tokens
                            if hasattr(usage, 'output_tokens_details') and usage.output_tokens_details:
                                if hasattr(usage.output_tokens_details, 'reasoning_tokens'):
                                    reasoning_tokens = usage.output_tokens_details.reasoning_tokens
                
                end_time = time.time()
                
                # è®¡ç®—æŒ‡æ ‡
                ttft = (first_token_time - start_time) if first_token_time else 0
                total_duration = end_time - start_time
                
                # æ˜¾ç¤ºæŒ‡æ ‡
                if total_tokens > 0:
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("â±ï¸ TTFT", f"{ttft:.2f}s")
                    with col2:
                        st.metric("âŒ› æ€»æ—¶é•¿", f"{total_duration:.2f}s")
                    with col3:
                        st.metric("ğŸ§  Reasoning", reasoning_tokens)
                    with col4:
                        st.metric("ğŸ“Š Total Tokens", total_tokens)
                
                # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
                st.session_state.messages.append({
                    "role": "assistant", 
                    "text": full_response
                })
        
        except Exception as e:
            st.error(f"âŒ é”™è¯¯: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
