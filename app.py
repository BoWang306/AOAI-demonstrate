import streamlit as st
import os
from openai import AzureOpenAI
import json
from datetime import datetime
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Azure OpenAI æ¨¡å‹æµ‹è¯•é—¨æˆ·",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #0078D4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .model-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .response-box {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #0078D4;
        margin: 1rem 0;
    }
    .metrics-box {
        background-color: #f9f9f9;
        padding: 0.8rem;
        border-radius: 0.3rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# å¯ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    "GPT-4.1": {
        "gpt-4.1-nano": "gpt-4.1-nano",
    },
    "GPT-5": {
        "gpt-5": "gpt-5",
        "gpt-5-nano": "gpt-5-nano",
        "gpt-5-pro": "gpt-5-pro",
    },
    "GPT-5.1": {
        "gpt-5.1-chat": "gpt-5.1-chat",
    },
    "GPT-5.2": {
        "gpt-5.2": "gpt-5.2",
        "gpt-5.2-chat": "gpt-5.2-chat",
        "gpt-5.2-chat-2": "gpt-5.2-chat",
        "gpt-5.2-codex": "gpt-5.2-codex",
    },
    "GPT-Realtime": {
        "gpt-realtime": "gpt-realtime",
    },
    "Grok": {
        "grok-4-fast-non-reasoning": "grok-4-fast-non-reasoning",
    }
}

# åˆå§‹åŒ– session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""
if 'api_base' not in st.session_state:
    st.session_state.api_base = ""
if 'api_version' not in st.session_state:
    st.session_state.api_version = "2024-02-15-preview"

def initialize_client(api_key, api_base, api_version):
    """åˆå§‹åŒ– Azure OpenAI å®¢æˆ·ç«¯"""
    try:
        client = AzureOpenAI(
            api_key=api_key,
            api_version=api_version,
            azure_endpoint=api_base
        )
        return client
    except Exception as e:
        st.error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None

def call_chat_completion(client, model, messages, temperature, max_tokens, top_p, stream=False):
    """è°ƒç”¨èŠå¤©å®Œæˆ API"""
    try:
        start_time = time.time()
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            stream=stream
        )
        
        if stream:
            return response, None
        else:
            end_time = time.time()
            latency = end_time - start_time
            
            return response, {
                "latency": latency,
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            }
    except Exception as e:
        st.error(f"API è°ƒç”¨å¤±è´¥: {str(e)}")
        return None, None

def main():
    # é¡µé¢æ ‡é¢˜
    st.markdown('<div class="main-header">ğŸ¤– Azure OpenAI æ¨¡å‹æµ‹è¯•é—¨æˆ·</div>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        
        # API é…ç½®
        st.subheader("API è®¾ç½®")
        api_key = st.text_input("API Key", type="password", value=st.session_state.api_key)
        api_base = st.text_input("API Base URL", value=st.session_state.api_base, 
                                 placeholder="https://your-resource.openai.azure.com/")
        api_version = st.text_input("API Version", value=st.session_state.api_version)
        
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            st.session_state.api_key = api_key
            st.session_state.api_base = api_base
            st.session_state.api_version = api_version
            st.success("é…ç½®å·²ä¿å­˜ï¼")
        
        st.divider()
        
        # æ¨¡å‹é€‰æ‹©
        st.subheader("ğŸ¯ æ¨¡å‹é€‰æ‹©")
        
        model_family = st.selectbox(
            "æ¨¡å‹ç³»åˆ—",
            options=list(AVAILABLE_MODELS.keys())
        )
        
        model_name = st.selectbox(
            "å…·ä½“æ¨¡å‹",
            options=list(AVAILABLE_MODELS[model_family].keys())
        )
        
        selected_model = AVAILABLE_MODELS[model_family][model_name]
        
        st.info(f"å½“å‰é€‰æ‹©: **{selected_model}**")
        
        st.divider()
        
        # å‚æ•°é…ç½®
        st.subheader("ğŸ”§ å‚æ•°è®¾ç½®")
        
        temperature = st.slider("Temperature", 0.0, 2.0, 0.7, 0.1)
        max_tokens = st.slider("Max Tokens", 100, 4000, 1000, 100)
        top_p = st.slider("Top P", 0.0, 1.0, 0.95, 0.05)
        stream_output = st.checkbox("æµå¼è¾“å‡º", value=False)
        
        st.divider()
        
        # æ¸…ç©ºå¯¹è¯å†å²
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.chat_history = []
            st.rerun()
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ èŠå¤©æµ‹è¯•", "ğŸ“ å•æ¬¡è°ƒç”¨", "ğŸ“Š æ‰¹é‡æµ‹è¯•", "ğŸ“– æ¨¡å‹ä¿¡æ¯"])
    
    # Tab 1: èŠå¤©æµ‹è¯•
    with tab1:
        st.header("èŠå¤©æ¨¡å¼æµ‹è¯•")
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        chat_container = st.container()
        with chat_container:
            for idx, msg in enumerate(st.session_state.chat_history):
                if msg["role"] == "user":
                    st.chat_message("user").write(msg["content"])
                else:
                    st.chat_message("assistant").write(msg["content"])
        
        # ç”¨æˆ·è¾“å…¥
        user_input = st.chat_input("è¾“å…¥æ‚¨çš„æ¶ˆæ¯...")
        
        if user_input:
            if not st.session_state.api_key or not st.session_state.api_base:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key å’Œ Base URL")
            else:
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": user_input
                })
                
                # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
                st.chat_message("user").write(user_input)
                
                # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
                messages = [{"role": msg["role"], "content": msg["content"]} 
                           for msg in st.session_state.chat_history]
                
                # åˆå§‹åŒ–å®¢æˆ·ç«¯
                client = initialize_client(
                    st.session_state.api_key,
                    st.session_state.api_base,
                    st.session_state.api_version
                )
                
                if client:
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå›å¤..."):
                        response, metrics = call_chat_completion(
                            client, selected_model, messages,
                            temperature, max_tokens, top_p, stream_output
                        )
                        
                        if response:
                            if stream_output:
                                # æµå¼è¾“å‡º
                                response_placeholder = st.empty()
                                full_response = ""
                                for chunk in response:
                                    if chunk.choices[0].delta.content:
                                        full_response += chunk.choices[0].delta.content
                                        response_placeholder.chat_message("assistant").write(full_response)
                                assistant_message = full_response
                            else:
                                # éæµå¼è¾“å‡º
                                assistant_message = response.choices[0].message.content
                                st.chat_message("assistant").write(assistant_message)
                                
                                # æ˜¾ç¤ºæŒ‡æ ‡
                                if metrics:
                                    col1, col2, col3, col4 = st.columns(4)
                                    col1.metric("å»¶è¿Ÿ", f"{metrics['latency']:.2f}s")
                                    col2.metric("è¾“å…¥ Tokens", metrics['prompt_tokens'])
                                    col3.metric("è¾“å‡º Tokens", metrics['completion_tokens'])
                                    col4.metric("æ€»è®¡ Tokens", metrics['total_tokens'])
                            
                            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                            st.session_state.chat_history.append({
                                "role": "assistant",
                                "content": assistant_message
                            })
                            
                            st.rerun()
    
    # Tab 2: å•æ¬¡è°ƒç”¨
    with tab2:
        st.header("å•æ¬¡ API è°ƒç”¨æµ‹è¯•")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            system_prompt = st.text_area("System Prompt (å¯é€‰)", 
                                        placeholder="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹...",
                                        height=100)
            user_prompt = st.text_area("User Prompt", 
                                      placeholder="è¾“å…¥ä½ çš„é—®é¢˜æˆ–æŒ‡ä»¤...",
                                      height=200)
            
            if st.button("ğŸš€ å‘é€è¯·æ±‚", type="primary"):
                if not st.session_state.api_key or not st.session_state.api_base:
                    st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key å’Œ Base URL")
                elif not user_prompt:
                    st.warning("âš ï¸ è¯·è¾“å…¥ User Prompt")
                else:
                    messages = []
                    if system_prompt:
                        messages.append({"role": "system", "content": system_prompt})
                    messages.append({"role": "user", "content": user_prompt})
                    
                    client = initialize_client(
                        st.session_state.api_key,
                        st.session_state.api_base,
                        st.session_state.api_version
                    )
                    
                    if client:
                        with st.spinner("æ­£åœ¨è°ƒç”¨ API..."):
                            response, metrics = call_chat_completion(
                                client, selected_model, messages,
                                temperature, max_tokens, top_p
                            )
                            
                            if response:
                                st.success("âœ… è°ƒç”¨æˆåŠŸï¼")
                                
                                # æ˜¾ç¤ºå“åº”
                                st.markdown("### ğŸ“¤ å“åº”å†…å®¹")
                                st.markdown(f'<div class="response-box">{response.choices[0].message.content}</div>', 
                                          unsafe_allow_html=True)
                                
                                # æ˜¾ç¤ºæŒ‡æ ‡
                                if metrics:
                                    st.markdown("### ğŸ“Š æ€§èƒ½æŒ‡æ ‡")
                                    col1, col2, col3, col4 = st.columns(4)
                                    col1.metric("â±ï¸ å»¶è¿Ÿ", f"{metrics['latency']:.2f}s")
                                    col2.metric("ğŸ“¥ è¾“å…¥ Tokens", metrics['prompt_tokens'])
                                    col3.metric("ğŸ“¤ è¾“å‡º Tokens", metrics['completion_tokens'])
                                    col4.metric("ğŸ“Š æ€»è®¡ Tokens", metrics['total_tokens'])
                                
                                # æ˜¾ç¤ºå®Œæ•´å“åº”
                                with st.expander("ğŸ” æŸ¥çœ‹å®Œæ•´å“åº” JSON"):
                                    st.json(response.model_dump())
        
        with col2:
            st.markdown("### ğŸ’¡ æç¤º")
            st.info("""
            **ä½¿ç”¨è¯´æ˜:**
            1. é…ç½® API ä¿¡æ¯
            2. é€‰æ‹©æ¨¡å‹
            3. è®¾ç½®å‚æ•°
            4. è¾“å…¥æç¤ºè¯
            5. ç‚¹å‡»å‘é€
            
            **æœ€ä½³å®è·µ:**
            - System Prompt å®šä¹‰è§’è‰²
            - User Prompt æè¿°ä»»åŠ¡
            - è°ƒæ•´å‚æ•°ä¼˜åŒ–è¾“å‡º
            """)
    
    # Tab 3: æ‰¹é‡æµ‹è¯•
    with tab3:
        st.header("æ‰¹é‡æµ‹è¯•å·¥å…·")
        
        st.markdown("### ğŸ“‹ æµ‹è¯•ç”¨ä¾‹é…ç½®")
        
        # å…è®¸ç”¨æˆ·ä¸Šä¼  JSON æ–‡ä»¶æˆ–æ‰‹åŠ¨è¾“å…¥
        upload_mode = st.radio("è¾“å…¥æ¨¡å¼", ["æ‰‹åŠ¨è¾“å…¥", "ä¸Šä¼  JSON æ–‡ä»¶"])
        
        test_cases = []
        
        if upload_mode == "æ‰‹åŠ¨è¾“å…¥":
            num_cases = st.number_input("æµ‹è¯•ç”¨ä¾‹æ•°é‡", min_value=1, max_value=10, value=3)
            
            for i in range(num_cases):
                with st.expander(f"æµ‹è¯•ç”¨ä¾‹ {i+1}", expanded=(i==0)):
                    case_name = st.text_input(f"ç”¨ä¾‹åç§° {i+1}", value=f"Test Case {i+1}", key=f"case_name_{i}")
                    case_prompt = st.text_area(f"Prompt {i+1}", key=f"case_prompt_{i}", height=100)
                    
                    if case_prompt:
                        test_cases.append({
                            "name": case_name,
                            "prompt": case_prompt
                        })
        else:
            uploaded_file = st.file_uploader("ä¸Šä¼ æµ‹è¯•ç”¨ä¾‹ JSON æ–‡ä»¶", type=['json'])
            if uploaded_file:
                try:
                    test_cases = json.load(uploaded_file)
                    st.success(f"âœ… æˆåŠŸåŠ è½½ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                except Exception as e:
                    st.error(f"âŒ JSON è§£æå¤±è´¥: {str(e)}")
        
        if st.button("ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•", type="primary"):
            if not test_cases:
                st.warning("âš ï¸ è¯·æ·»åŠ æµ‹è¯•ç”¨ä¾‹")
            elif not st.session_state.api_key or not st.session_state.api_base:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key å’Œ Base URL")
            else:
                client = initialize_client(
                    st.session_state.api_key,
                    st.session_state.api_base,
                    st.session_state.api_version
                )
                
                if client:
                    results = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, case in enumerate(test_cases):
                        status_text.text(f"æ­£åœ¨æµ‹è¯•: {case['name']} ({idx+1}/{len(test_cases)})")
                        
                        messages = [{"role": "user", "content": case['prompt']}]
                        response, metrics = call_chat_completion(
                            client, selected_model, messages,
                            temperature, max_tokens, top_p
                        )
                        
                        if response:
                            results.append({
                                "name": case['name'],
                                "prompt": case['prompt'],
                                "response": response.choices[0].message.content,
                                "metrics": metrics
                            })
                        
                        progress_bar.progress((idx + 1) / len(test_cases))
                    
                    status_text.text("âœ… æµ‹è¯•å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.markdown("### ğŸ“Š æµ‹è¯•ç»“æœ")
                    
                    for result in results:
                        with st.expander(f"ğŸ“ {result['name']}", expanded=False):
                            st.markdown("**Prompt:**")
                            st.code(result['prompt'])
                            
                            st.markdown("**Response:**")
                            st.markdown(f'<div class="response-box">{result["response"]}</div>', 
                                      unsafe_allow_html=True)
                            
                            if result['metrics']:
                                col1, col2, col3, col4 = st.columns(4)
                                col1.metric("å»¶è¿Ÿ", f"{result['metrics']['latency']:.2f}s")
                                col2.metric("è¾“å…¥", result['metrics']['prompt_tokens'])
                                col3.metric("è¾“å‡º", result['metrics']['completion_tokens'])
                                col4.metric("æ€»è®¡", result['metrics']['total_tokens'])
                    
                    # æ±‡æ€»ç»Ÿè®¡
                    st.markdown("### ğŸ“ˆ æ±‡æ€»ç»Ÿè®¡")
                    total_latency = sum(r['metrics']['latency'] for r in results if r['metrics'])
                    avg_latency = total_latency / len(results) if results else 0
                    total_tokens = sum(r['metrics']['total_tokens'] for r in results if r['metrics'])
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("å¹³å‡å»¶è¿Ÿ", f"{avg_latency:.2f}s")
                    col2.metric("æ€» Tokens", total_tokens)
                    col3.metric("æˆåŠŸç‡", f"{len(results)}/{len(test_cases)}")
                    
                    # å¯¼å‡ºç»“æœ
                    if st.button("ğŸ’¾ å¯¼å‡ºç»“æœ"):
                        result_json = json.dumps(results, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="ä¸‹è½½ JSON",
                            data=result_json,
                            file_name=f"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
    
    # Tab 4: æ¨¡å‹ä¿¡æ¯
    with tab4:
        st.header("ğŸ“– å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        
        for family, models in AVAILABLE_MODELS.items():
            with st.expander(f"ğŸ“¦ {family}", expanded=True):
                for name, model_id in models.items():
                    col1, col2 = st.columns([1, 2])
                    with col1:
                        st.markdown(f"**{name}**")
                    with col2:
                        st.code(model_id)
        
        st.divider()
        
        st.markdown("### ğŸ“š ä½¿ç”¨æŒ‡å—")
        st.markdown("""
        #### ğŸ¯ å¿«é€Ÿå¼€å§‹
        1. åœ¨ä¾§è¾¹æ é…ç½® Azure OpenAI API ä¿¡æ¯
        2. é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹
        3. è°ƒæ•´æ¨¡å‹å‚æ•°ï¼ˆTemperatureã€Max Tokens ç­‰ï¼‰
        4. é€‰æ‹©æµ‹è¯•æ¨¡å¼å¼€å§‹ä½¿ç”¨
        
        #### ğŸ’¬ èŠå¤©æµ‹è¯•
        - æ”¯æŒå¤šè½®å¯¹è¯
        - ä¿ç•™å¯¹è¯å†å²
        - å®æ—¶äº¤äº’æµ‹è¯•
        
        #### ğŸ“ å•æ¬¡è°ƒç”¨
        - å¿«é€Ÿæµ‹è¯•å•ä¸ªè¯·æ±‚
        - æŸ¥çœ‹è¯¦ç»†å“åº”å’Œæ€§èƒ½æŒ‡æ ‡
        - æ”¯æŒè‡ªå®šä¹‰ System Prompt
        
        #### ğŸ“Š æ‰¹é‡æµ‹è¯•
        - åŒæ—¶æµ‹è¯•å¤šä¸ªç”¨ä¾‹
        - å¯¹æ¯”ä¸åŒè¾“å…¥çš„è¾“å‡º
        - å¯¼å‡ºæµ‹è¯•ç»“æœ
        
        #### âš™ï¸ å‚æ•°è¯´æ˜
        - **Temperature**: æ§åˆ¶è¾“å‡ºéšæœºæ€§ (0-2)
        - **Max Tokens**: æœ€å¤§è¾“å‡ºé•¿åº¦
        - **Top P**: æ ¸é‡‡æ ·å‚æ•° (0-1)
        - **Stream**: å¯ç”¨æµå¼è¾“å‡º
        
        #### ğŸ” å®‰å…¨æç¤º
        - API Key ä»…ä¿å­˜åœ¨å½“å‰ä¼šè¯
        - ä¸ä¼šä¸Šä¼ åˆ°ä»»ä½•æœåŠ¡å™¨
        - å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®æ•æ„Ÿä¿¡æ¯
        """)

if __name__ == "__main__":
    main()
