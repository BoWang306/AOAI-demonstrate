import streamlit as st
import os
from openai import AzureOpenAI
import json
from datetime import datetime
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Azure OpenAI æ¨¡å‹æµ‹è¯•é—¨æˆ·",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #0078D4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .model-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .response-box {
        background-color: #e8f4f8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #0078D4;
        margin: 1rem 0;
    }
    .metrics-box {
        background-color: #f9f9f9;
        padding: 0.8rem;
        border-radius: 0.3rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# å¯ç”¨æ¨¡å‹åˆ—è¡¨å’ŒAPIæ”¯æŒä¿¡æ¯
# æ ¹æ®Azure OpenAIå®˜æ–¹æ–‡æ¡£æ›´æ–° (2025-01)
AVAILABLE_MODELS = {
    "GPT-4.1 ç³»åˆ—": {
        "models": {
            "gpt-4.1": {"name": "gpt-4.1", "api": "Chat Completions", "desc": "æ ‡å‡†ç‰ˆæœ¬"},
            "gpt-4.1-nano": {"name": "gpt-4.1-nano", "api": "Chat Completions", "desc": "è½»é‡å¿«é€Ÿç‰ˆ"},
            "gpt-4.1-mini": {"name": "gpt-4.1-mini", "api": "Chat Completions", "desc": "è¿·ä½ ç‰ˆæœ¬"},
        }
    },
    "GPT-5 ç³»åˆ—": {
        "models": {
            "gpt-5": {"name": "gpt-5", "api": "Chat Completions", "desc": "æ ‡å‡†ç‰ˆæœ¬ (éœ€æ³¨å†Œ)"},
            "gpt-5-mini": {"name": "gpt-5-mini", "api": "Chat Completions", "desc": "è¿·ä½ ç‰ˆæœ¬"},
            "gpt-5-nano": {"name": "gpt-5-nano", "api": "Chat Completions", "desc": "çº³ç±³ç‰ˆæœ¬"},
            "gpt-5-chat": {"name": "gpt-5-chat", "api": "Chat Completions", "desc": "å¯¹è¯ä¼˜åŒ–ç‰ˆ"},
            "gpt-5-pro": {"name": "gpt-5-pro", "api": "Responses API Only", "desc": "ä¸“ä¸šç‰ˆ (éœ€æ³¨å†Œ)"},
        }
    },
    "GPT-5.1 ç³»åˆ—": {
        "models": {
            "gpt-5.1": {"name": "gpt-5.1", "api": "Chat Completions", "desc": "æ ‡å‡†ç‰ˆæœ¬ (éœ€æ³¨å†Œ)"},
            "gpt-5.1-chat": {"name": "gpt-5.1-chat", "api": "Chat Completions", "desc": "å¯¹è¯ç‰ˆæœ¬ (Preview)"},
        }
    },
    "GPT-5.2 ç³»åˆ—": {
        "models": {
            "gpt-5.2": {"name": "gpt-5.2", "api": "Chat Completions", "desc": "æ ‡å‡†ç‰ˆæœ¬ (éœ€æ³¨å†Œ)"},
            "gpt-5.2-chat": {"name": "gpt-5.2-chat", "api": "Chat Completions", "desc": "å¯¹è¯ç‰ˆæœ¬ (Preview)"},
            "gpt-5.2-codex": {"name": "gpt-5.2-codex", "api": "Chat Completions", "desc": "ä»£ç ä¼˜åŒ–ç‰ˆ (éœ€æ³¨å†Œ)"},
        }
    },
    "GPT-4o ç³»åˆ—": {
        "models": {
            "gpt-4o": {"name": "gpt-4o", "api": "Chat Completions", "desc": "GPT-4 Omni æ ‡å‡†ç‰ˆ"},
            "gpt-4o-mini": {"name": "gpt-4o-mini", "api": "Chat Completions", "desc": "GPT-4 Omni è¿·ä½ ç‰ˆ"},
        }
    },
    "GPT-4 Turbo": {
        "models": {
            "gpt-4-turbo": {"name": "gpt-4", "api": "Chat Completions", "desc": "GPT-4 Turbo"},
        }
    },
    "GPT-3.5 ç³»åˆ—": {
        "models": {
            "gpt-35-turbo": {"name": "gpt-35-turbo", "api": "Chat Completions", "desc": "GPT-3.5 Turbo"},
        }
    },
    "o ç³»åˆ— (æ¨ç†æ¨¡å‹)": {
        "models": {
            "o1": {"name": "o1", "api": "Chat Completions", "desc": "æ¨ç†æ¨¡å‹"},
            "o1-mini": {"name": "o1-mini", "api": "Chat Completions", "desc": "æ¨ç†æ¨¡å‹è¿·ä½ ç‰ˆ"},
            "o3-mini": {"name": "o3-mini", "api": "Chat Completions", "desc": "æ¨ç†æ¨¡å‹ o3-mini"},
        }
    },
    "Grok ç³»åˆ—": {
        "models": {
            "grok-4-fast-non-reasoning": {"name": "grok-4-fast-non-reasoning", "api": "Chat Completions", "desc": "å¿«é€Ÿæ¨ç†ç‰ˆæœ¬"},
        }
    }
}

# åˆå§‹åŒ– session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'api_key' not in st.session_state:
    st.session_state.api_key = ""
if 'api_base' not in st.session_state:
    st.session_state.api_base = ""
if 'api_version' not in st.session_state:
    st.session_state.api_version = "2024-02-15-preview"

def initialize_client(api_key, api_base, api_version):
    """åˆå§‹åŒ– Azure OpenAI å®¢æˆ·ç«¯"""
    try:
        client = AzureOpenAI(
            api_key=api_key,
            api_version=api_version,
            azure_endpoint=api_base
        )
        return client
    except Exception as e:
        st.error(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None

def call_chat_completion(client, model, messages, temperature, max_tokens, top_p, stream=False):
    """è°ƒç”¨èŠå¤©å®Œæˆ API"""
    try:
        start_time = time.time()
        
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            stream=stream
        )
        
        if stream:
            return response, None
        else:
            end_time = time.time()
            latency = end_time - start_time
            
            return response, {
                "latency": latency,
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            }
    except Exception as e:
        error_msg = str(e)
        
        # è§£æå¸¸è§é”™è¯¯å¹¶æä¾›å‹å¥½æç¤º
        if "OperationNotSupported" in error_msg:
            st.error(f"âŒ **API ä¸æ”¯æŒé”™è¯¯**")
            st.error(f"æ¨¡å‹ `{model}` ä¸æ”¯æŒ Chat Completions API")
            st.info("ğŸ’¡ **è§£å†³æ–¹æ¡ˆ**:")
            st.info("1. æ£€æŸ¥è¯¥æ¨¡å‹æ˜¯å¦éœ€è¦ä½¿ç”¨ Responses API")
            st.info("2. é€‰æ‹©å…¶ä»–æ”¯æŒ Chat Completions API çš„æ¨¡å‹")
            st.info("3. å‚è€ƒæ–‡æ¡£: https://learn.microsoft.com/azure/ai-foundry/openai/")
        elif "DeploymentNotFound" in error_msg:
            st.error(f"âŒ **éƒ¨ç½²æœªæ‰¾åˆ°**")
            st.error(f"æ¨¡å‹ `{model}` æœªåœ¨æ‚¨çš„ Azure OpenAI èµ„æºä¸­éƒ¨ç½²")
            st.info("ğŸ’¡ **è§£å†³æ–¹æ¡ˆ**:")
            st.info("1. åœ¨ Azure OpenAI Studio ä¸­éƒ¨ç½²è¯¥æ¨¡å‹")
            st.info("2. ç¡®ä¿ä½¿ç”¨çš„æ˜¯éƒ¨ç½²åç§°è€Œä¸æ˜¯æ¨¡å‹åç§°")
            st.info("3. æ£€æŸ¥éƒ¨ç½²æ˜¯å¦åœ¨æ­£ç¡®çš„åŒºåŸŸ")
        elif "invalid_request_error" in error_msg:
            st.error(f"âŒ **è¯·æ±‚å‚æ•°é”™è¯¯**")
            st.error(f"è¯¦ç»†ä¿¡æ¯: {error_msg}")
            st.info("ğŸ’¡ **è§£å†³æ–¹æ¡ˆ**:")
            st.info("1. æ£€æŸ¥ Temperature ç­‰å‚æ•°æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†…")
            st.info("2. æ£€æŸ¥ Max Tokens è®¾ç½®æ˜¯å¦åˆç†")
            st.info("3. æŸäº›æ¨ç†æ¨¡å‹ä¸æ”¯æŒ temperature å‚æ•°")
        elif "401" in error_msg or "Unauthorized" in error_msg:
            st.error(f"âŒ **è®¤è¯å¤±è´¥**")
            st.error("API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ")
            st.info("ğŸ’¡ **è§£å†³æ–¹æ¡ˆ**:")
            st.info("1. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®")
            st.info("2. ç¡®è®¤ API Key æœªè¿‡æœŸ")
            st.info("3. åœ¨ Azure Portal ä¸­é‡æ–°ç”Ÿæˆå¯†é’¥")
        elif "429" in error_msg or "RateLimitReached" in error_msg:
            st.error(f"âŒ **é€Ÿç‡é™åˆ¶**")
            st.error("è¯·æ±‚é¢‘ç‡è¿‡é«˜æˆ–é…é¢å·²ç”¨å®Œ")
            st.info("ğŸ’¡ **è§£å†³æ–¹æ¡ˆ**:")
            st.info("1. ç­‰å¾…å‡ ç§’åé‡è¯•")
            st.info("2. æ£€æŸ¥ Azure è®¢é˜…é…é¢")
            st.info("3. è€ƒè™‘å‡çº§é…é¢æˆ–ä½¿ç”¨ä¸åŒçš„åŒºåŸŸ")
        else:
            st.error(f"âŒ **API è°ƒç”¨å¤±è´¥**")
            st.error(f"é”™è¯¯è¯¦æƒ…: {error_msg}")
            st.info("ğŸ’¡ **å¸¸è§è§£å†³æ–¹æ¡ˆ**:")
            st.info("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            st.info("2. éªŒè¯ API é…ç½®æ˜¯å¦æ­£ç¡®")
            st.info("3. æŸ¥çœ‹ Azure Portal ä¸­çš„æœåŠ¡çŠ¶æ€")
        
        return None, None

def main():
    # é¡µé¢æ ‡é¢˜
    st.markdown('<div class="main-header">ğŸ¤– Azure OpenAI æ¨¡å‹æµ‹è¯•é—¨æˆ·</div>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        
        # API é…ç½®
        st.subheader("API è®¾ç½®")
        api_key = st.text_input("API Key", type="password", value=st.session_state.api_key)
        api_base = st.text_input("API Base URL", value=st.session_state.api_base, 
                                 placeholder="https://your-resource.openai.azure.com/")
        api_version = st.text_input("API Version", value=st.session_state.api_version)
        
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            st.session_state.api_key = api_key
            st.session_state.api_base = api_base
            st.session_state.api_version = api_version
            st.success("é…ç½®å·²ä¿å­˜ï¼")
        
        st.divider()
        
        # æ¨¡å‹é€‰æ‹©
        st.subheader("ğŸ¯ æ¨¡å‹é€‰æ‹©")
        
        model_family = st.selectbox(
            "æ¨¡å‹ç³»åˆ—",
            options=list(AVAILABLE_MODELS.keys())
        )
        
        model_options = AVAILABLE_MODELS[model_family]["models"]
        model_name = st.selectbox(
            "å…·ä½“æ¨¡å‹",
            options=list(model_options.keys()),
            format_func=lambda x: f"{x} - {model_options[x]['desc']}"
        )
        
        selected_model_info = model_options[model_name]
        selected_model = selected_model_info["name"]
        api_type = selected_model_info["api"]
        
        st.info(f"**å½“å‰é€‰æ‹©**: {selected_model}")
        
        # API æ”¯æŒæç¤º
        if "Responses API Only" in api_type:
            st.warning(f"âš ï¸ **æ³¨æ„**: {selected_model} ä»…æ”¯æŒ Responses APIï¼Œä¸æ”¯æŒ Chat Completions API")
        elif "éœ€æ³¨å†Œ" in selected_model_info["desc"]:
            st.warning(f"âš ï¸ **æ³¨æ„**: {selected_model} éœ€è¦ç”³è¯·æ³¨å†Œæ‰èƒ½ä½¿ç”¨")
        
        if api_type == "Chat Completions":
            st.success(f"âœ… æ”¯æŒ Chat Completions API")
        
        # æ˜¾ç¤ºæ¨¡å‹è¯¦æƒ…
        with st.expander("ğŸ“‹ æ¨¡å‹è¯¦ç»†ä¿¡æ¯"):
            st.write(f"- **æ¨¡å‹åç§°**: {selected_model}")
            st.write(f"- **API ç±»å‹**: {api_type}")
            st.write(f"- **æè¿°**: {selected_model_info['desc']}")
        
        st.divider()
        
        # å‚æ•°é…ç½®
        st.subheader("ğŸ”§ å‚æ•°è®¾ç½®")
        
        temperature = st.slider("Temperature", 0.0, 2.0, 0.7, 0.1)
        max_tokens = st.slider("Max Tokens", 100, 4000, 1000, 100)
        top_p = st.slider("Top P", 0.0, 1.0, 0.95, 0.05)
        stream_output = st.checkbox("æµå¼è¾“å‡º", value=False)
        
        st.divider()
        
        # æ¸…ç©ºå¯¹è¯å†å²
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.chat_history = []
            st.rerun()
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ èŠå¤©æµ‹è¯•", "ğŸ“ å•æ¬¡è°ƒç”¨", "ğŸ“Š æ‰¹é‡æµ‹è¯•", "ğŸ“– æ¨¡å‹ä¿¡æ¯"])
    
    # Tab 1: èŠå¤©æµ‹è¯•
    with tab1:
        st.header("èŠå¤©æ¨¡å¼æµ‹è¯•")
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        chat_container = st.container()
        with chat_container:
            for idx, msg in enumerate(st.session_state.chat_history):
                if msg["role"] == "user":
                    st.chat_message("user").write(msg["content"])
                else:
                    st.chat_message("assistant").write(msg["content"])
        
        # ç”¨æˆ·è¾“å…¥
        user_input = st.chat_input("è¾“å…¥æ‚¨çš„æ¶ˆæ¯...")
        
        if user_input:
            if not st.session_state.api_key or not st.session_state.api_base:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key å’Œ Base URL")
            else:
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": user_input
                })
                
                # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
                st.chat_message("user").write(user_input)
                
                # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
                messages = [{"role": msg["role"], "content": msg["content"]} 
                           for msg in st.session_state.chat_history]
                
                # åˆå§‹åŒ–å®¢æˆ·ç«¯
                client = initialize_client(
                    st.session_state.api_key,
                    st.session_state.api_base,
                    st.session_state.api_version
                )
                
                if client:
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå›å¤..."):
                        response, metrics = call_chat_completion(
                            client, selected_model, messages,
                            temperature, max_tokens, top_p, stream_output
                        )
                        
                        if response:
                            if stream_output:
                                # æµå¼è¾“å‡º
                                response_placeholder = st.empty()
                                full_response = ""
                                for chunk in response:
                                    if chunk.choices[0].delta.content:
                                        full_response += chunk.choices[0].delta.content
                                        response_placeholder.chat_message("assistant").write(full_response)
                                assistant_message = full_response
                            else:
                                # éæµå¼è¾“å‡º
                                assistant_message = response.choices[0].message.content
                                st.chat_message("assistant").write(assistant_message)
                                
                                # æ˜¾ç¤ºæŒ‡æ ‡
                                if metrics:
                                    col1, col2, col3, col4 = st.columns(4)
                                    col1.metric("å»¶è¿Ÿ", f"{metrics['latency']:.2f}s")
                                    col2.metric("è¾“å…¥ Tokens", metrics['prompt_tokens'])
                                    col3.metric("è¾“å‡º Tokens", metrics['completion_tokens'])
                                    col4.metric("æ€»è®¡ Tokens", metrics['total_tokens'])
                            
                            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                            st.session_state.chat_history.append({
                                "role": "assistant",
                                "content": assistant_message
                            })
                            
                            st.rerun()
    
    # Tab 2: å•æ¬¡è°ƒç”¨
    with tab2:
        st.header("å•æ¬¡ API è°ƒç”¨æµ‹è¯•")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            system_prompt = st.text_area("System Prompt (å¯é€‰)", 
                                        placeholder="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹...",
                                        height=100)
            user_prompt = st.text_area("User Prompt", 
                                      placeholder="è¾“å…¥ä½ çš„é—®é¢˜æˆ–æŒ‡ä»¤...",
                                      height=200)
            
            if st.button("ğŸš€ å‘é€è¯·æ±‚", type="primary"):
                if not st.session_state.api_key or not st.session_state.api_base:
                    st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key å’Œ Base URL")
                elif not user_prompt:
                    st.warning("âš ï¸ è¯·è¾“å…¥ User Prompt")
                else:
                    messages = []
                    if system_prompt:
                        messages.append({"role": "system", "content": system_prompt})
                    messages.append({"role": "user", "content": user_prompt})
                    
                    client = initialize_client(
                        st.session_state.api_key,
                        st.session_state.api_base,
                        st.session_state.api_version
                    )
                    
                    if client:
                        with st.spinner("æ­£åœ¨è°ƒç”¨ API..."):
                            response, metrics = call_chat_completion(
                                client, selected_model, messages,
                                temperature, max_tokens, top_p
                            )
                            
                            if response:
                                st.success("âœ… è°ƒç”¨æˆåŠŸï¼")
                                
                                # æ˜¾ç¤ºå“åº”
                                st.markdown("### ğŸ“¤ å“åº”å†…å®¹")
                                st.markdown(f'<div class="response-box">{response.choices[0].message.content}</div>', 
                                          unsafe_allow_html=True)
                                
                                # æ˜¾ç¤ºæŒ‡æ ‡
                                if metrics:
                                    st.markdown("### ğŸ“Š æ€§èƒ½æŒ‡æ ‡")
                                    col1, col2, col3, col4 = st.columns(4)
                                    col1.metric("â±ï¸ å»¶è¿Ÿ", f"{metrics['latency']:.2f}s")
                                    col2.metric("ğŸ“¥ è¾“å…¥ Tokens", metrics['prompt_tokens'])
                                    col3.metric("ğŸ“¤ è¾“å‡º Tokens", metrics['completion_tokens'])
                                    col4.metric("ğŸ“Š æ€»è®¡ Tokens", metrics['total_tokens'])
                                
                                # æ˜¾ç¤ºå®Œæ•´å“åº”
                                with st.expander("ğŸ” æŸ¥çœ‹å®Œæ•´å“åº” JSON"):
                                    st.json(response.model_dump())
        
        with col2:
            st.markdown("### ğŸ’¡ æç¤º")
            st.info("""
            **ä½¿ç”¨è¯´æ˜:**
            1. é…ç½® API ä¿¡æ¯
            2. é€‰æ‹©æ¨¡å‹
            3. è®¾ç½®å‚æ•°
            4. è¾“å…¥æç¤ºè¯
            5. ç‚¹å‡»å‘é€
            
            **æœ€ä½³å®è·µ:**
            - System Prompt å®šä¹‰è§’è‰²
            - User Prompt æè¿°ä»»åŠ¡
            - è°ƒæ•´å‚æ•°ä¼˜åŒ–è¾“å‡º
            """)
    
    # Tab 3: æ‰¹é‡æµ‹è¯•
    with tab3:
        st.header("æ‰¹é‡æµ‹è¯•å·¥å…·")
        
        st.markdown("### ğŸ“‹ æµ‹è¯•ç”¨ä¾‹é…ç½®")
        
        # å…è®¸ç”¨æˆ·ä¸Šä¼  JSON æ–‡ä»¶æˆ–æ‰‹åŠ¨è¾“å…¥
        upload_mode = st.radio("è¾“å…¥æ¨¡å¼", ["æ‰‹åŠ¨è¾“å…¥", "ä¸Šä¼  JSON æ–‡ä»¶"])
        
        test_cases = []
        
        if upload_mode == "æ‰‹åŠ¨è¾“å…¥":
            num_cases = st.number_input("æµ‹è¯•ç”¨ä¾‹æ•°é‡", min_value=1, max_value=10, value=3)
            
            for i in range(num_cases):
                with st.expander(f"æµ‹è¯•ç”¨ä¾‹ {i+1}", expanded=(i==0)):
                    case_name = st.text_input(f"ç”¨ä¾‹åç§° {i+1}", value=f"Test Case {i+1}", key=f"case_name_{i}")
                    case_prompt = st.text_area(f"Prompt {i+1}", key=f"case_prompt_{i}", height=100)
                    
                    if case_prompt:
                        test_cases.append({
                            "name": case_name,
                            "prompt": case_prompt
                        })
        else:
            uploaded_file = st.file_uploader("ä¸Šä¼ æµ‹è¯•ç”¨ä¾‹ JSON æ–‡ä»¶", type=['json'])
            if uploaded_file:
                try:
                    test_cases = json.load(uploaded_file)
                    st.success(f"âœ… æˆåŠŸåŠ è½½ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                except Exception as e:
                    st.error(f"âŒ JSON è§£æå¤±è´¥: {str(e)}")
        
        if st.button("ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•", type="primary"):
            if not test_cases:
                st.warning("âš ï¸ è¯·æ·»åŠ æµ‹è¯•ç”¨ä¾‹")
            elif not st.session_state.api_key or not st.session_state.api_base:
                st.error("âŒ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key å’Œ Base URL")
            else:
                client = initialize_client(
                    st.session_state.api_key,
                    st.session_state.api_base,
                    st.session_state.api_version
                )
                
                if client:
                    results = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for idx, case in enumerate(test_cases):
                        status_text.text(f"æ­£åœ¨æµ‹è¯•: {case['name']} ({idx+1}/{len(test_cases)})")
                        
                        messages = [{"role": "user", "content": case['prompt']}]
                        response, metrics = call_chat_completion(
                            client, selected_model, messages,
                            temperature, max_tokens, top_p
                        )
                        
                        if response:
                            results.append({
                                "name": case['name'],
                                "prompt": case['prompt'],
                                "response": response.choices[0].message.content,
                                "metrics": metrics
                            })
                        
                        progress_bar.progress((idx + 1) / len(test_cases))
                    
                    status_text.text("âœ… æµ‹è¯•å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.markdown("### ğŸ“Š æµ‹è¯•ç»“æœ")
                    
                    for result in results:
                        with st.expander(f"ğŸ“ {result['name']}", expanded=False):
                            st.markdown("**Prompt:**")
                            st.code(result['prompt'])
                            
                            st.markdown("**Response:**")
                            st.markdown(f'<div class="response-box">{result["response"]}</div>', 
                                      unsafe_allow_html=True)
                            
                            if result['metrics']:
                                col1, col2, col3, col4 = st.columns(4)
                                col1.metric("å»¶è¿Ÿ", f"{result['metrics']['latency']:.2f}s")
                                col2.metric("è¾“å…¥", result['metrics']['prompt_tokens'])
                                col3.metric("è¾“å‡º", result['metrics']['completion_tokens'])
                                col4.metric("æ€»è®¡", result['metrics']['total_tokens'])
                    
                    # æ±‡æ€»ç»Ÿè®¡
                    st.markdown("### ğŸ“ˆ æ±‡æ€»ç»Ÿè®¡")
                    total_latency = sum(r['metrics']['latency'] for r in results if r['metrics'])
                    avg_latency = total_latency / len(results) if results else 0
                    total_tokens = sum(r['metrics']['total_tokens'] for r in results if r['metrics'])
                    
                    col1, col2, col3 = st.columns(3)
                    col1.metric("å¹³å‡å»¶è¿Ÿ", f"{avg_latency:.2f}s")
                    col2.metric("æ€» Tokens", total_tokens)
                    col3.metric("æˆåŠŸç‡", f"{len(results)}/{len(test_cases)}")
                    
                    # å¯¼å‡ºç»“æœ
                    if st.button("ğŸ’¾ å¯¼å‡ºç»“æœ"):
                        result_json = json.dumps(results, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="ä¸‹è½½ JSON",
                            data=result_json,
                            file_name=f"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
    
    # Tab 4: æ¨¡å‹ä¿¡æ¯
    with tab4:
        st.header("ğŸ“– å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        
        st.info("ğŸ’¡ æ ¹æ® Azure OpenAI å®˜æ–¹æ–‡æ¡£æ›´æ–° (2025-01)")
        
        for family, family_data in AVAILABLE_MODELS.items():
            with st.expander(f"ğŸ“¦ {family}", expanded=True):
                models = family_data["models"]
                for name, model_info in models.items():
                    col1, col2, col3 = st.columns([2, 2, 3])
                    with col1:
                        st.markdown(f"**{name}**")
                    with col2:
                        st.code(model_info["name"])
                    with col3:
                        # API ç±»å‹æ ‡ç­¾
                        if model_info["api"] == "Chat Completions":
                            st.success(f"âœ… {model_info['api']}")
                        else:
                            st.warning(f"âš ï¸ {model_info['api']}")
                        st.caption(model_info["desc"])
        
        st.divider()
        
        st.markdown("### âš ï¸ é‡è¦æç¤º")
        st.warning("""
        **æ¨¡å‹è®¿é—®è¦æ±‚**:
        - ğŸ”’ æ ‡è®°ä¸º"éœ€æ³¨å†Œ"çš„æ¨¡å‹éœ€è¦ç”³è¯·è®¿é—®æƒé™
        - ğŸ“ æŸäº›æ¨¡å‹ä»…æ”¯æŒç‰¹å®šçš„ APIï¼ˆå¦‚ Responses APIï¼‰
        - ğŸŒ ä¸åŒåŒºåŸŸå¯ç”¨çš„æ¨¡å‹å¯èƒ½ä¸åŒ
        - ğŸ’° ä¸åŒæ¨¡å‹æœ‰ä¸åŒçš„å®šä»·
        
        **ç”³è¯·è®¿é—®**:
        - GPT-5 ç³»åˆ—: https://aka.ms/oai/gpt5access
        - GPT-Image ç³»åˆ—: https://aka.ms/oai/gptimage1access
        
        **æ–‡æ¡£å‚è€ƒ**:
        - Azure OpenAI æ–‡æ¡£: https://learn.microsoft.com/azure/ai-foundry/openai/
        - æ¨¡å‹åˆ—è¡¨: https://learn.microsoft.com/azure/ai-foundry/foundry-models/
        """)
        
        st.divider()
        
        st.markdown("### ğŸ“š ä½¿ç”¨æŒ‡å—")
        st.markdown("""
        #### ğŸ¯ å¿«é€Ÿå¼€å§‹
        1. åœ¨ä¾§è¾¹æ é…ç½® Azure OpenAI API ä¿¡æ¯
        2. é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹ï¼ˆæ³¨æ„APIæ”¯æŒç±»å‹ï¼‰
        3. ç¡®ä¿æ¨¡å‹å·²åœ¨ Azure OpenAI Studio ä¸­éƒ¨ç½²
        4. è°ƒæ•´æ¨¡å‹å‚æ•°ï¼ˆTemperatureã€Max Tokens ç­‰ï¼‰
        5. é€‰æ‹©æµ‹è¯•æ¨¡å¼å¼€å§‹ä½¿ç”¨
        
        #### ğŸ’¬ èŠå¤©æµ‹è¯•
        - æ”¯æŒå¤šè½®å¯¹è¯
        - ä¿ç•™å¯¹è¯å†å²
        - å®æ—¶äº¤äº’æµ‹è¯•
        - é€‚ç”¨äºæ”¯æŒ Chat Completions API çš„æ¨¡å‹
        
        #### ğŸ“ å•æ¬¡è°ƒç”¨
        - å¿«é€Ÿæµ‹è¯•å•ä¸ªè¯·æ±‚
        - æŸ¥çœ‹è¯¦ç»†å“åº”å’Œæ€§èƒ½æŒ‡æ ‡
        - æ”¯æŒè‡ªå®šä¹‰ System Prompt
        - æŸ¥çœ‹å®Œæ•´çš„ JSON å“åº”
        
        #### ğŸ“Š æ‰¹é‡æµ‹è¯•
        - åŒæ—¶æµ‹è¯•å¤šä¸ªç”¨ä¾‹
        - å¯¹æ¯”ä¸åŒè¾“å…¥çš„è¾“å‡º
        - å¯¼å‡ºæµ‹è¯•ç»“æœ
        - æ€§èƒ½åŸºå‡†æµ‹è¯•
        
        #### âš™ï¸ å‚æ•°è¯´æ˜
        - **Temperature**: æ§åˆ¶è¾“å‡ºéšæœºæ€§ (0-2ï¼ŒæŸäº›æ¨ç†æ¨¡å‹ä¸æ”¯æŒ)
        - **Max Tokens**: æœ€å¤§è¾“å‡ºé•¿åº¦
        - **Top P**: æ ¸é‡‡æ ·å‚æ•° (0-1)
        - **Stream**: å¯ç”¨æµå¼è¾“å‡º
        
        #### âš ï¸ å¸¸è§é”™è¯¯
        - **OperationNotSupported**: æ¨¡å‹ä¸æ”¯æŒè¯¥ API ç±»å‹
        - **DeploymentNotFound**: æ¨¡å‹æœªéƒ¨ç½²æˆ–éƒ¨ç½²åç§°é”™è¯¯
        - **Unauthorized**: API Key æ— æ•ˆæˆ–è¿‡æœŸ
        - **RateLimitReached**: é€Ÿç‡é™åˆ¶æˆ–é…é¢ä¸è¶³
        
        #### ğŸ” å®‰å…¨æç¤º
        - API Key ä»…ä¿å­˜åœ¨å½“å‰ä¼šè¯
        - ä¸ä¼šä¸Šä¼ åˆ°ä»»ä½•æœåŠ¡å™¨
        - å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®æ•æ„Ÿä¿¡æ¯
        - å®šæœŸè½®æ¢ API å¯†é’¥
        """)

if __name__ == "__main__":
    main()
