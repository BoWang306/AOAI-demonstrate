# Azure OpenAI 模型测试门户 - 使用指南

## 📖 目录

1. [快速开始](#快速开始)
2. [功能介绍](#功能介绍)
3. [使用教程](#使用教程)
4. [常见问题](#常见问题)
5. [最佳实践](#最佳实践)

## 🚀 快速开始

### 方法一：直接启动

```bash
# 1. 安装依赖
pip install -r requirements.txt

# 2. 启动应用
streamlit run app.py
```

### 方法二：使用启动脚本

```bash
# 直接运行启动脚本
./start.sh
```

### 方法三：使用环境变量

```bash
# 1. 复制配置文件模板
cp .env.example .env

# 2. 编辑 .env 文件，填入你的配置
nano .env

# 3. 启动应用
streamlit run app.py
```

## 🎯 功能介绍

### 1. 💬 聊天测试模式

**适用场景**: 需要与 AI 进行多轮对话交互

**主要功能**:
- ✅ 保留完整对话历史
- ✅ 支持连续对话上下文
- ✅ 实时性能监控
- ✅ 流式/非流式输出切换

**使用步骤**:
1. 在侧边栏配置 API 信息
2. 选择要测试的模型
3. 在聊天框输入消息
4. 查看 AI 回复和性能指标

### 2. 📝 单次调用模式

**适用场景**: 测试单个 API 请求，查看详细响应

**主要功能**:
- ✅ 自定义 System Prompt
- ✅ 查看完整响应 JSON
- ✅ 详细性能指标
- ✅ 快速原型测试

**使用步骤**:
1. 输入 System Prompt（定义 AI 角色）
2. 输入 User Prompt（你的问题或任务）
3. 点击"发送请求"
4. 查看响应、指标和完整 JSON

### 3. 📊 批量测试模式

**适用场景**: 同时测试多个场景，对比不同输入的效果

**主要功能**:
- ✅ 支持多个测试用例
- ✅ 手动输入或 JSON 文件上传
- ✅ 自动化批量运行
- ✅ 结果汇总和导出

**使用步骤**:
1. 选择输入模式（手动或 JSON）
2. 配置测试用例
3. 点击"开始批量测试"
4. 查看结果并导出

**JSON 格式示例**:
```json
[
  {
    "name": "测试用例1",
    "prompt": "你的问题或任务"
  },
  {
    "name": "测试用例2",
    "prompt": "另一个问题"
  }
]
```

### 4. 📖 模型信息

**主要内容**:
- 📋 完整的可用模型列表
- 📚 使用指南和参数说明
- 💡 最佳实践建议

## 📚 使用教程

### 第一步：配置 API

#### 获取 Azure OpenAI API 信息

1. **登录 Azure Portal**
   - 访问 https://portal.azure.com
   - 登录你的 Azure 账户

2. **找到 Azure OpenAI 资源**
   - 在搜索栏输入 "Azure OpenAI"
   - 选择你的 Azure OpenAI 资源

3. **获取密钥和端点**
   - 在左侧菜单选择 "密钥和终结点"
   - 复制以下信息：
     - **API Key**: KEY 1 或 KEY 2
     - **Endpoint**: 终结点 URL

#### 在应用中配置

**方式一：通过界面配置**
1. 在侧边栏找到"⚙️ 配置"部分
2. 输入以下信息：
   - API Key: 粘贴你的密钥
   - API Base URL: 粘贴终结点 URL（确保以 `/` 结尾）
   - API Version: 使用默认值或指定版本
3. 点击"💾 保存配置"

**方式二：使用环境变量**
1. 复制配置模板：
   ```bash
   cp .env.example .env
   ```

2. 编辑 `.env` 文件：
   ```env
   AZURE_OPENAI_API_KEY=你的密钥
   AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
   AZURE_OPENAI_API_VERSION=2024-02-15-preview
   ```

3. 重启应用以加载配置

#### 测试配置

使用配置助手工具验证配置：
```bash
streamlit run config_helper.py
```

### 第二步：选择模型

在侧边栏的"🎯 模型选择"部分：

1. **选择模型系列**
   - GPT-4.1 系列：最新的 GPT-4 模型
   - GPT-5 系列：包含 nano、标准、pro 版本
   - GPT-5.1 系列：Chat 专用版本
   - GPT-5.2 系列：多个变体，包括 Codex
   - GPT-Realtime：实时对话模型
   - Grok：快速推理模型

2. **选择具体模型**
   - 根据需求选择合适的模型
   - 查看当前选择的模型名称

### 第三步：调整参数

在侧边栏的"🔧 参数设置"部分：

#### Temperature (温度)
- **范围**: 0.0 - 2.0
- **默认**: 0.7
- **说明**: 
  - 低值 (0.0 - 0.3): 输出更确定、一致
  - 中值 (0.4 - 0.8): 平衡创造性和一致性
  - 高值 (0.9 - 2.0): 输出更随机、有创造性

**使用建议**:
- 代码生成、数据分析：0.1 - 0.3
- 常规对话、问答：0.5 - 0.7
- 创意写作、头脑风暴：0.8 - 1.2

#### Max Tokens (最大令牌数)
- **范围**: 100 - 4000
- **默认**: 1000
- **说明**: 控制生成文本的最大长度

**使用建议**:
- 简短回答：100 - 300
- 中等长度：500 - 1000
- 长文本：1500 - 4000

#### Top P (核采样)
- **范围**: 0.0 - 1.0
- **默认**: 0.95
- **说明**: 控制考虑的候选词汇范围

**使用建议**:
- 保持默认值 0.95 通常效果最好
- 与 Temperature 配合使用

#### 流式输出
- **选项**: 开启/关闭
- **默认**: 关闭
- **说明**: 
  - 开启：实时显示生成的文本（类似 ChatGPT）
  - 关闭：等待完整响应后显示

### 第四步：开始测试

#### 聊天测试

1. 在聊天框输入消息
2. 按 Enter 发送
3. 查看 AI 回复
4. 继续对话或调整参数

**示例对话**:
```
你：你好，请介绍一下你自己
AI：我是一个 AI 助手...

你：你能帮我做什么？
AI：我可以帮助你...
```

#### 单次调用

1. **输入 System Prompt（可选）**
   ```
   你是一个专业的 Python 编程助手，擅长编写清晰、高效的代码。
   ```

2. **输入 User Prompt**
   ```
   写一个 Python 函数，计算两个数的最大公约数。
   ```

3. **点击"🚀 发送请求"**

4. **查看结果**
   - 响应内容
   - 性能指标（延迟、Token 数量）
   - 完整 JSON 响应

#### 批量测试

**方法一：手动输入**

1. 选择"手动输入"模式
2. 设置测试用例数量（1-10）
3. 为每个用例填写：
   - 用例名称
   - Prompt 内容
4. 点击"🚀 开始批量测试"
5. 查看所有结果和汇总统计

**方法二：JSON 文件**

1. 准备 JSON 文件（参考 `test_cases_example.json`）
2. 选择"上传 JSON 文件"模式
3. 上传文件
4. 点击"🚀 开始批量测试"
5. 查看结果并导出

**导出结果**:
- 点击"💾 导出结果"
- 下载 JSON 文件
- 包含所有测试用例的完整响应和指标

## ❓ 常见问题

### Q1: 如何获取 Azure OpenAI API Key？

**A**: 
1. 登录 Azure Portal (https://portal.azure.com)
2. 找到你的 Azure OpenAI 资源
3. 在"密钥和终结点"页面获取

### Q2: API Base URL 格式是什么？

**A**: 
- 格式：`https://<resource-name>.openai.azure.com/`
- 示例：`https://my-openai.openai.azure.com/`
- ⚠️ 确保 URL 以 `/` 结尾

### Q3: 显示"模型不存在"错误怎么办？

**A**: 
1. 检查模型是否已在 Azure OpenAI Studio 中部署
2. 确认使用的是**部署名称**而不是模型名称
3. 确保模型部署状态为"成功"

### Q4: API 调用失败怎么办？

**A**: 检查以下几点：
1. ✅ API Key 是否正确
2. ✅ API Base URL 格式是否正确
3. ✅ API Version 是否支持
4. ✅ 模型部署是否成功
5. ✅ Azure 订阅配额是否充足
6. ✅ 网络连接是否正常

### Q5: 如何选择合适的模型？

**A**: 根据使用场景选择：
- **快速响应**: gpt-4.1-nano, gpt-5-nano
- **标准任务**: gpt-5, gpt-5.1-chat
- **高质量输出**: gpt-5-pro, gpt-5.2
- **代码生成**: gpt-5.2-codex
- **实时对话**: gpt-realtime
- **快速推理**: grok-4-fast-non-reasoning

### Q6: 如何优化响应速度？

**A**: 
1. 使用 nano 系列模型
2. 降低 Max Tokens 设置
3. 使用流式输出
4. 简化 Prompt 内容

### Q7: 如何优化输出质量？

**A**: 
1. 使用 pro 系列模型
2. 提供清晰的 System Prompt
3. 调整 Temperature 参数
4. 使用示例指导输出格式

### Q8: 批量测试支持多少个用例？

**A**: 
- 手动输入：1-10 个
- JSON 文件：无限制（建议不超过 100 个）

### Q9: 如何保存配置？

**A**: 
- 方式一：在应用中点击"保存配置"（会话级别）
- 方式二：创建 `.env` 文件（持久化）

### Q10: 流式输出和非流式输出有什么区别？

**A**: 
- **流式**: 实时显示生成过程，用户体验好，无法获取完整指标
- **非流式**: 等待完整响应，可获取详细性能指标

## 💡 最佳实践

### 1. System Prompt 设计

**好的 System Prompt 示例**:
```
你是一个专业的技术文档撰写助手。你的回答应该：
1. 结构清晰，使用标题和列表
2. 语言简洁专业
3. 包含代码示例（如适用）
4. 提供实用建议
```

**避免**:
- 过于宽泛："你是一个助手"
- 自相矛盾："既要专业又要幽默"
- 过度限制："只用一句话回答"

### 2. Prompt 工程技巧

**使用具体指令**:
❌ "写个函数"
✅ "用 Python 写一个函数，接收一个整数列表，返回去重后的列表"

**提供示例**:
```
请按照以下格式回复：

问题：[用户问题]
分析：[问题分析]
解决方案：[具体方案]
代码示例：[代码]
```

**分步骤说明**:
```
请帮我完成以下任务：
1. 分析给定的数据
2. 找出主要趋势
3. 提供3个改进建议
4. 给出具体实施步骤
```

### 3. 参数调优

**创意任务**:
```
Temperature: 0.8 - 1.0
Top P: 0.95
Max Tokens: 1500+
```

**技术任务**:
```
Temperature: 0.1 - 0.3
Top P: 0.95
Max Tokens: 1000 - 2000
```

**对话任务**:
```
Temperature: 0.6 - 0.7
Top P: 0.95
Max Tokens: 500 - 1000
Stream: 开启
```

### 4. 成本优化

**降低成本的方法**:
1. ✅ 使用 nano 模型处理简单任务
2. ✅ 精简 Prompt 内容
3. ✅ 设置合理的 Max Tokens
4. ✅ 缓存常见回复
5. ✅ 批量处理相似请求

### 5. 测试策略

**开发阶段**:
- 使用单次调用快速迭代
- 调整参数找到最佳配置
- 记录成功的 Prompt 模板

**验证阶段**:
- 使用批量测试验证一致性
- 测试边界情况
- 对比不同模型效果

**生产阶段**:
- 监控性能指标
- 定期评估输出质量
- 优化高频场景

### 6. 安全建议

**保护敏感信息**:
1. ✅ 使用环境变量存储 API Key
2. ✅ 不要将 `.env` 文件提交到版本控制
3. ✅ 定期轮换 API Key
4. ✅ 使用专用的开发环境密钥

**输入验证**:
1. ✅ 过滤敏感信息
2. ✅ 限制输入长度
3. ✅ 验证输入格式

### 7. 故障排查

**问题诊断步骤**:
1. 使用配置助手测试连接
2. 检查错误信息
3. 验证配置信息
4. 查看 Azure Portal 日志
5. 测试简单请求
6. 逐步增加复杂度

## 📞 获取帮助

如果遇到问题：
1. 查看本文档的常见问题部分
2. 使用配置助手验证设置
3. 查看 Azure OpenAI 官方文档
4. 联系技术支持

---

**祝使用愉快！🚀**
